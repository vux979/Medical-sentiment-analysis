{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vux979/Medical-sentiment-analysis/blob/main/colab_%E6%95%B4%E4%BD%93%E8%BF%90%E8%A1%8C%EF%BC%88%E5%B7%B2%E6%9B%B4%E6%94%B9%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFepKL-w_-Xr",
        "outputId": "1a9c0fd3-c4da-4631-e449-959a5c0ddec1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar 14 14:55:36 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    56W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uwCcFm570Dk"
      },
      "source": [
        "# 下载并处理数据集"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 数据下载"
      ],
      "metadata": {
        "id": "W57QaO099NZz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQlLc_GbpjWZ"
      },
      "source": [
        "[kaggle数据集下载参考网址](https://segmentfault.com/a/1190000022134947)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH0vAGj_pGuv",
        "outputId": "c5c2af7b-3e44-4369-c834-3b76a9159e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.63.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zAx79hydpMoC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "token = {\"username\":\"shuxizhang\",\"key\":\"bb59cfc7fa45f101dcf52ee15438874d\"}\n",
        "# 我的室友就用我的号吧，如果是其他的访问者还是改一下token\n",
        "with open('/content/kaggle.json', 'w') as file:\n",
        "  json.dump(token, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6D5hj7iPpcq9"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VnG6cZBIpdZP"
      },
      "outputs": [],
      "source": [
        "!cp /content/kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_q3NK7FPpfXz"
      },
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7ChVE3bpuen",
        "outputId": "f5742fbf-84c1-47d8-a911-e8966cc848f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- ./kaggle-dataset is now set to: /yelp\n"
          ]
        }
      ],
      "source": [
        "!kaggle config set -n ./kaggle-dataset -v /yelp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao-Fb6NJqAum",
        "outputId": "9ca26943-3ed3-463a-b1d7-ac9980b3029b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yelp-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d yelp-dataset/yelp-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MklY2KidqcLP",
        "outputId": "6f27ff67-e2a1-4371-8e27-9815ec2b3939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset_User_Agreement.pdf\t     yelp_academic_dataset_checkin.json\n",
            "kaggle.json\t\t\t     yelp_academic_dataset_review.json\n",
            "sample_data\t\t\t     yelp_academic_dataset_tip.json\n",
            "transformers\t\t\t     yelp_academic_dataset_user.json\n",
            "yelp_academic_dataset_business.json  yelp-dataset.zip\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohADLNkGqqGQ",
        "outputId": "2aac01dd-2077-4599-b425-c6b0ad5556d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  yelp-dataset.zip\n",
            "replace Dataset_User_Agreement.pdf? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip yelp-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHsfpwWK6cxz"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Nq6F_G79ba"
      },
      "source": [
        "## 处理数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_RJFb4M6ec0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyn-7dvQ7iA9"
      },
      "outputs": [],
      "source": [
        "s = \"./yelp_academic_dataset_business.json\"\n",
        "\n",
        "data_business = []\n",
        "\n",
        "with open(s, 'r', encoding='UTF-8') as load_f:\n",
        "    for line in tqdm(load_f):\n",
        "        data_business.append(json.loads(line))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R__8Oeqd7mG8"
      },
      "outputs": [],
      "source": [
        "# 商店信息的数量\n",
        "len(data_business)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwH4ktao7o8y"
      },
      "outputs": [],
      "source": [
        "# 查看商店信息的存储格式\n",
        "data_business[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-XgoWZZ7qxM"
      },
      "outputs": [],
      "source": [
        "# 找到 categories 中包括 str1 & str2 这两个类的商店\n",
        "str1 = 'Health & Medical'\n",
        "str2 = 'Doctors'\n",
        "\n",
        "business_hmd = []\n",
        "for i in tqdm(range(len(data_business))):\n",
        "    if data_business[i][\"categories\"] != None: # categories 不为空值\n",
        "        flag = data_business[i][\"categories\"].rfind(str1) # 找不到 str1 就返回 -1\n",
        "        if flag != -1:\n",
        "            flag = data_business[i][\"categories\"].rfind(str2) # 找不到 str2 就返回 -1\n",
        "            if flag != -1:\n",
        "                business_hmd.append(data_business[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU7uQGFI8EYG"
      },
      "outputs": [],
      "source": [
        "len(business_hmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vgA7iGL8G_S"
      },
      "outputs": [],
      "source": [
        "business_hmd[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del(data_business) # 清内存，删除列表\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Ngkdl7JTAkvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVIVqhBG8L9v"
      },
      "source": [
        "### 抽取商店id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6a1DLXh8JGM"
      },
      "outputs": [],
      "source": [
        "business_hmd_id = []\n",
        "for element in tqdm(business_hmd):\n",
        "    business_hmd_id.append(element[\"business_id\"])\n",
        "len(business_hmd_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del(business_hmd) # 清内存\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "VOGHSalm8yZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgkIQDRb8Q1J"
      },
      "source": [
        "### 读取评论"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"./yelp_academic_dataset_review.json\"\n",
        "reviews_hmd = []\n",
        "with open(s, 'r', encoding='UTF-8') as load_f:\n",
        "  for line in tqdm(load_f):\n",
        "    line_dict = json.loads(line)\n",
        "    if line_dict['business_id'] in business_hmd_id:\n",
        "      reviews_hmd.append(line_dict)"
      ],
      "metadata": {
        "id": "ooWb-rzyGYbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(reviews_hmd)"
      ],
      "metadata": {
        "id": "XOO2YXolHNQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD95ktB28hI6"
      },
      "source": [
        "### 提取正负样本"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l46ZhReG8c0L"
      },
      "outputs": [],
      "source": [
        "pos = []\n",
        "neg = []\n",
        "mid = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uOxO7d58nkM"
      },
      "outputs": [],
      "source": [
        "def cleanReview(subject):\n",
        "    newSubject = re.sub(r'\\n', '', subject)\n",
        "    newSubject = re.sub(r\"\\'\", \"'\", newSubject)\n",
        "    return newSubject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu6ilDUm8pgm"
      },
      "outputs": [],
      "source": [
        "for element in tqdm(reviews_hmd):\n",
        "    if element['stars'] >= 4.0:\n",
        "        pos.append(cleanReview(element['text']))\n",
        "    elif element['stars'] <=2.0:\n",
        "        neg.append(cleanReview(element['text']))\n",
        "    else:\n",
        "        mid.append(cleanReview(element['text']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('pos: ', len(pos), '\\n', 'neg: ', len(neg), '\\n', 'mid: ', len(mid))"
      ],
      "metadata": {
        "id": "tBRrvhQo85tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pos = pd.DataFrame(columns=['']) # 创建dataframe， 定义一个没有名字的空列\n",
        "df_neg = pd.DataFrame(columns=[''])\n",
        "df_mid = pd.DataFrame(columns=[''])\n",
        "\n",
        "df_pos[''] = pos # 给空列赋值\n",
        "df_neg[''] = neg\n",
        "df_mid[''] = mid"
      ],
      "metadata": {
        "id": "KZaq_-Gx9_2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 训练"
      ],
      "metadata": {
        "id": "DKDuOgMa9k5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "LyocRi8f9y_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.utils.data as Data\n",
        "import  torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(torch.__version__, device)"
      ],
      "metadata": {
        "id": "IXt2rLGr9mIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadfile():\n",
        "    combined=np.concatenate((pos[:30000], neg[:30000]))\n",
        "    # print(type(pos[0][0])) <str>\n",
        "    y = np.concatenate((np.ones(len(pos[:30000]),dtype=int), np.zeros(len(neg[:30000]),dtype=int)))\n",
        "    # pos 1, neg 0\n",
        "\n",
        "    return combined, y"
      ],
      "metadata": {
        "id": "t_EgHlAC-La7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#构造数据\n",
        "def data_classfier():\n",
        "    combined,y = loadfile()\n",
        "    data = combined\n",
        "    labels = y\n",
        "    print('Shape of data tensor:', len(data))\n",
        "    print('Shape of label tensor:', len(labels))\n",
        "    \n",
        "\n",
        "\n",
        "    indices = np.arange(data.shape[0])\n",
        "    np.random.shuffle(indices)  #打乱\n",
        "    data = data[indices]\n",
        "\n",
        "    labels = labels[indices]\n",
        "    \n",
        "    VALIDATION_SPLIT = 0.5\n",
        "    nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "    x_train = data[:-nb_validation_samples]\n",
        "    y_train = labels[:-nb_validation_samples]\n",
        "    x_val = data[-nb_validation_samples:]\n",
        "    y_val = labels[-nb_validation_samples:]\n",
        "    return x_train,y_train,x_val,y_val"
      ],
      "metadata": {
        "id": "jRmy7iUt-TET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train,x_val,y_val = data_classfier()"
      ],
      "metadata": {
        "id": "c1IjZZKr-UwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(x_train))\n",
        "print(type(y_train))\n",
        "print(type(x_val))\n",
        "print(type(y_val))\n",
        "print(len(x_train))\n",
        "print(len(y_train))\n",
        "print(len(x_val))\n",
        "print(len(y_val))"
      ],
      "metadata": {
        "id": "hEZxWKq--XAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 导入bert"
      ],
      "metadata": {
        "id": "smme_DPD-coQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "# 这里我们调用bert-base模型，同时模型的词典经过小写处理\n",
        "model_name = 'bert-base-uncased'\n",
        "# 读取模型对应的tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, cache_dir='./transformers/bert-base-uncased/')\n",
        "# 载入模型\n",
        "model = BertModel.from_pretrained(model_name, cache_dir='./transformers/bert-base-uncased/')"
      ],
      "metadata": {
        "id": "Z3w_OK6r-Z8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "hztlv-WK-h3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "for i in  range(len(x_train)):\n",
        "    train_data.append([])\n",
        "    train_data[i].append(x_train[i])\n",
        "    train_data[i].append(y_train[i])"
      ],
      "metadata": {
        "id": "jFGIQztb-jX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "for i in  range(len(x_val)):\n",
        "    test_data.append([])\n",
        "    test_data[i].append(x_val[i])\n",
        "    test_data[i].append(y_val[i])"
      ],
      "metadata": {
        "id": "aEeckZHH-kpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretreatment(original_data):\n",
        "    i = 0\n",
        "    for element in tqdm(original_data):\n",
        "        temporary = []\n",
        "        original_data[i][0] = torch.tensor(tokenizer.encode(element[0], add_special_tokens=True, max_length = 512, padding='max_length', truncation=True))\n",
        "        temporary.append(element[1])\n",
        "        original_data[i][1] = torch.tensor(temporary)\n",
        "        i = i+1\n",
        "    features =  torch.cat([original_data[i][0].unsqueeze(0).long() for i in range(len(original_data))])\n",
        "    labels =  torch.cat( [original_data[i][1].long() for i in range(len(original_data))], 0)\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "P04GkhpD-mor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = Data.TensorDataset(*(pretreatment(train_data)))\n",
        "test_set = Data.TensorDataset(*(pretreatment(test_data)))"
      ],
      "metadata": {
        "id": "BfmU1YU3-n01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "train_iter = Data.DataLoader(train_set, batch_size)# , shuffle=True)\n",
        "test_iter = Data.DataLoader(test_set, batch_size)# , shuffle=True)"
      ],
      "metadata": {
        "id": "O0ZYu-yu-pFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型定义"
      ],
      "metadata": {
        "id": "Dx1B1vnH-8Nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalMaxPool1d(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GlobalMaxPool1d, self).__init__()\n",
        "    def forward(self, x):\n",
        "         # x shape: (batch_size, channel, seq_len)\n",
        "        return F.max_pool1d(x, kernel_size=x.shape[2]) # shape: (batch_size, channel, 1)"
      ],
      "metadata": {
        "id": "_b2zOm8H-qQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, embed_size, kernel_sizes, num_channels):\n",
        "        super(TextCNN, self).__init__()\n",
        "        # self.embedding = nn.Embedding(len(vocab), embed_size)\n",
        "        # 不参与训练的嵌入层\n",
        "        # self.constant_embedding = nn.Embedding(len(vocab), embed_size)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.decoder_1 = nn.Linear(sum(num_channels), 256)\n",
        "        self.decoder_2 = nn.Linear(256, 2)\n",
        "        # 时序最大池化层没有权重，所以可以共用一个实例\n",
        "        self.pool = GlobalMaxPool1d()\n",
        "        self.convs = nn.ModuleList()  # 创建多个一维卷积层\n",
        "        \n",
        "        for c, k in zip(num_channels, kernel_sizes):\n",
        "            self.convs.append(nn.Conv1d(in_channels = embed_size, \n",
        "                                        out_channels = c, \n",
        "                                        kernel_size = k))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs = model(inputs)[0] #shape（512， 768）\n",
        "        embeddings = outputs # (batch, seq_len, embed_size)\n",
        "        # 根据Conv1D要求的输入格式，将词向量维，即一维卷积层的通道维(即词向量那一维)，变换到前一维\n",
        "        embeddings = embeddings.permute(0, 2, 1) # 交换维度的函数\n",
        "        # 对于每个一维卷积层，在时序最大池化后会得到一个形状为(批量大小, 通道大小, 1)的\n",
        "        # Tensor。使用flatten函数去掉最后一维，然后在通道维上连结\n",
        "        encoding = torch.cat([self.pool(F.relu(conv(embeddings))).squeeze(-1) for conv in self.convs], dim=1)\n",
        "        # 应用丢弃法后使用全连接层得到输出\n",
        "        middle = self.decoder_1(self.dropout(encoding))\n",
        "        \n",
        "        outputs = self.decoder_2(self.dropout(F.relu(middle)))\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "m8oUUI7R--k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size, kernel_sizes, nums_channels = 768, [3, 4, 5], [100, 100, 100]\n",
        "net = TextCNN(embed_size, kernel_sizes, nums_channels)"
      ],
      "metadata": {
        "id": "ux9PPAgj_EmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(data_iter, net, device=None):\n",
        "    if device is None and isinstance(net, torch.nn.Module):\n",
        "        # 如果没指定device就使用net的device\n",
        "        device = list(net.parameters())[0].device \n",
        "    acc_sum, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in tqdm(data_iter, desc ='evaluate'):\n",
        "            if isinstance(net, torch.nn.Module):\n",
        "                net.eval() # 评估模式, 这会关闭dropout\n",
        "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
        "                net.train() # 改回训练模式\n",
        "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
        "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
        "                    # 将is_training设置成False\n",
        "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
        "                else:\n",
        "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
        "            n += y.shape[0]\n",
        "    return acc_sum / n"
      ],
      "metadata": {
        "id": "OOTQrFBc_KnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_iter, test_iter, net, loss, optimizer, device, num_epochs):\n",
        "    net = net.to(device)\n",
        "    print(\"training on \", device)\n",
        "    batch_count = 0\n",
        "    best_acc = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        print(time.strftime(\"%Y-%m-%d \\t %H:%M:%S\", time.localtime()), end='\\t')\n",
        "        for X, y in tqdm(train_iter, desc ='train'):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y) \n",
        "            optimizer.zero_grad()\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            train_l_sum += l.cpu().item()\n",
        "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
        "            n += y.shape[0]\n",
        "            batch_count += 1\n",
        "        test_acc = evaluate_accuracy(test_iter, net)\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            print(\"saving\", end='\\t')\n",
        "            PATH = \"./BertBaseEpoch1_yelp_\" + str(best_acc) + \".pth\"\n",
        "            torch.save(net, PATH) \n",
        "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
        "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
      ],
      "metadata": {
        "id": "amDYhMY1_L_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr, num_epochs = 0.001, 10\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)"
      ],
      "metadata": {
        "id": "8LWHygPZ_N-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 模型测试"
      ],
      "metadata": {
        "id": "Rw-nDzsa_WFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(net, sentence):\n",
        "    \"\"\"sentence是词语的列表\"\"\"\n",
        "    device = list(net.parameters())[0].device\n",
        "    sentence = torch.tensor(tokenizer.encode(s, add_special_tokens=True, max_length = 512, padding='max_length', truncation=True), device=device)\n",
        "    result = net(sentence.view((1, -1)))\n",
        "    m = nn.Softmax(dim=1)\n",
        "    print(m(result))\n",
        "    label = torch.argmax(result, dim=1)\n",
        "    return 'positive' if label.item() == 1 else 'negative'"
      ],
      "metadata": {
        "id": "H6cdzq7W_P8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"请输入一句与医疗相关的英文：\")\n",
        "s = input() \n",
        "print(predict_sentiment(net, s))"
      ],
      "metadata": {
        "id": "1zLwMMZ4_YWm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "colab-整体运行（已更改）.ipynb",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPO0AUVVW9vOQGcZTAX+B+g",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}